---
title: "Schertz Compensation Data Pipeline - Documented Version"
author: "Compensation Review Project"
date: today
format: html
editor: source
---

## Introduction

This document explains each component of the compensation data pipeline. It's designed to help you understand what each piece of code does and why, so you can maintain and extend it confidently.

The pipeline has one job: take five messy Excel files and produce a single, clean, audit-ready dataset—while proving nothing was lost or corrupted along the way.

------------------------------------------------------------------------

## Setup: Loading Libraries and Source Files

```{r}
#| label: setup
#| message: false

# Core data manipulation
library(readxl)    # Read Excel files into R
library(dplyr)     # Data manipulation (filter, mutate, select, etc.)
library(tidyr)     # Reshaping data (pivot_longer, pivot_wider)
library(stringr)   # String manipulation (str_replace, str_detect, etc.)
library(janitor)   # Data cleaning utilities (clean_names)
library(purrr)     # Functional programming (map, map_dfr, etc.)

# Output and visualization
library(flextable) # Create formatted tables for reports
library(ggplot2)   # Data visualization
library(scales)    # Formatting for axes (dollar_format, percent, etc.)

# Source our custom pipeline components
# These are the four R files that contain our functions
source("schertz_config.R")         # Configuration: what files, what corrections
source("schertz_profiler.R")       # Tools for examining new files
source("schertz_processing.R")     # Core data transformation functions
source("schertz_reconciliation.R") # Validation and audit reporting
```

**What this does**: Loads all the R packages we need, then loads our four custom files that contain the pipeline functions. The `source()` function runs an R script and makes all its functions available to use.

------------------------------------------------------------------------

## Step 1: Verify Configuration

Before processing anything, we confirm that our configuration is correct and all source files exist.

```{r}
#| label: verify-config

# Display the file registry - this tells the pipeline which files to process
# and what "structure type" each one has (early vs late format)
base::cat("=== FILE REGISTRY ===\n\n")
print(file_registry)

# Check that each file in the registry actually exists on disk
# This prevents cryptic errors later if a file is missing or misnamed
base::cat("\n=== FILE STATUS ===\n\n")

file_check <- purrr::map_dfr(
  # Iterate through each row number in the registry
  base::seq_len(base::nrow(file_registry)),
  function(i) {
    # Build the full path: data_raw folder + filename
    filepath <- base::file.path(paths$data_raw, file_registry$filename[i])
    
    # Return a one-row tibble with the check result
    dplyr::tibble(
      fiscal_year = file_registry$fiscal_year[i],
      filename = file_registry$filename[i],
      exists = base::file.exists(filepath)  # TRUE if file found, FALSE if not
    )
  }
)

print(file_check)

# If any file is missing, stop immediately with a clear error
# Better to fail here than produce incomplete results
if (!base::all(file_check$exists)) {
  stop("Missing files! Cannot proceed.")
}

# Show the name corrections that will be applied
# These fix known issues like "Pitts jr" -> "Pitts Jr."
base::cat("\n=== NAME CORRECTIONS (", base::nrow(name_corrections), " rules) ===\n\n")
print(name_corrections)

# Show the key entities we'll verify are present
# These are people who MUST appear or something is wrong
base::cat("\n=== KEY ENTITIES TO VERIFY (", base::nrow(key_entities), ") ===\n\n")
print(key_entities)
```

**What this does**:

-   `file_registry` is a table in the config that lists each Excel file and its structure type
-   `purrr::map_dfr()` loops through each file and checks if it exists, returning results as a data frame
-   `file.path()` safely combines folder path and filename (handles Mac/Windows differences)
-   `file.exists()` returns TRUE/FALSE for whether the file is there
-   `stop()` halts execution with an error message—we want to fail loudly if files are missing

------------------------------------------------------------------------

## Step 2: Run the Pipeline

The pipeline runs in five stages. We save intermediate results so the reconciliation module can verify each stage worked correctly.

```{r}
#| label: run-pipeline

# run_pipeline_with_intermediates() is defined in schertz_processing.R
# It calls five internal stages in sequence and returns all intermediate results

pipeline_results <- run_pipeline_with_intermediates(
  registry = file_registry,      # Which files to process
  corrections = name_corrections, # Name fixes to apply
  data_path = paths$data_raw      # Where to find the Excel files
)

# Extract the three key data frames from the results
# We need all three for the reconciliation checkpoints

# ^ Data immediately after import, before any cleaning
#   Used by Checkpoint A to verify row counts match source files
combined_df <- pipeline_results$combined


# ^ Data after cleaning, with name_std and employee_key columns
#   Used by Checkpoints B and C for name/key validation
cleaned_df <- pipeline_results$cleaned


# ^ Final long-format data ready for analysis
#   Used by Checkpoint D for completeness verification
final_df <- pipeline_results$final

```

**What this does**:

-   `run_pipeline_with_intermediates()` is our master function that orchestrates everything
-   It returns a list with three data frames at different stages of processing
-   We extract these separately because different reconciliation checkpoints need different stages
-   `combined` = raw import (text columns, before parsing)
-   `cleaned` = after parsing dates/currency, standardizing names, creating keys
-   `final` = after pivoting to long format and selecting final columns

------------------------------------------------------------------------

## Step 3: Run Reconciliation

This is the critical audit step. Four checkpoints verify data integrity.

```{r}
#| label: run-reconciliation

# run_reconciliation() is defined in schertz_reconciliation.R
# It runs all four checkpoints and returns structured results

reconciliation <- run_reconciliation(
  combined_df = combined_df,   # For Checkpoint A (source reconciliation)
  cleaned_df = cleaned_df,     # For Checkpoints B & C (names and keys)
  final_df = final_df,         # For Checkpoint D (completeness)
  registry = file_registry,    # File info for Checkpoint A
  corrections = name_corrections, # To show which similar names are already handled
  entities = key_entities,     # Who must be present (Checkpoint D)
  external = external_totals   # Published totals to compare against (Checkpoint D)
)
```

**What this does**:

-   Runs four validation checkpoints in sequence
-   Each checkpoint returns PASS/FAIL plus detailed results
-   The `reconciliation` object contains everything needed for the HTML report

------------------------------------------------------------------------



### Checkpoint A: Source Reconciliation

**Purpose**: Prove that the number of rows and total dollars in our imported data exactly match what's in the source Excel files. If these don't match, something was dropped or corrupted during import.

```{r}
#| label: checkpoint-a-details

# The reconciliation object contains detailed results for each checkpoint
# checkpoint_a$details is a data frame with one row per source file

reconciliation$checkpoint_a$details |>
  dplyr::mutate(
    # Format dollar amounts for readability
    # scales::dollar() adds $ sign and comma separators
    source_total = scales::dollar(source_total, accuracy = 1),
    imported_total = scales::dollar(imported_total, accuracy = 1),
    total_diff = scales::dollar(total_diff, accuracy = 1)
  ) |>
  # flextable creates a nicely formatted table for HTML output
  flextable::flextable() |>
  flextable::autofit() |>  # Automatically size columns to fit content
  flextable::set_caption("Checkpoint A: Source File Reconciliation")
```

**What this does**:

-   Shows source file row count vs imported row count (should be identical)
-   Shows source file total earnings vs imported total (should match within rounding)
-   `rows_match` and `totals_match` columns show TRUE/FALSE for each file
-   If any show FALSE, something went wrong during import

**How it works internally** (in schertz_reconciliation.R):

1.  For each file in the registry, read the Excel file directly and sum earnings columns
2.  Compare to the same fiscal year in our combined_df
3.  Flag any discrepancies

------------------------------------------------------------------------

### Checkpoint B: Name Variations

**Purpose**: Detect spelling variations that could cause the same person to appear as two different people, or cause filters to silently miss records.

```{r}
#| label: checkpoint-b-details

# Summary shows counts of issues found
reconciliation$checkpoint_b$summary |>
  flextable::flextable() |>
  flextable::autofit() |>
  flextable::set_caption("Checkpoint B: Name Variation Summary")
```

```{r}
#| label: checkpoint-b-similar-names

# If similar names were found, show them for review
# These are names within edit distance 1-2 of each other

if (base::nrow(reconciliation$checkpoint_b$similar_names) > 0) {
  reconciliation$checkpoint_b$similar_names |>
    dplyr::slice_head(n = 30) |>  # Show first 30 only (could be many)
    flextable::flextable() |>
    flextable::autofit() |>
    flextable::set_caption("Similar Name Pairs (first 30)")
} else {
  base::cat("No similar name pairs found.")
}
```

**What this does**:

-   Finds names that differ by just 1-2 characters (edit distance)
-   These might be the same person with slightly different spellings across years
-   "Possibly corrected" column shows if an existing correction rule might handle it
-   Review these and add new corrections to config as needed

**How edit distance works**:

-   "Smith, John" vs "Smith, Jon" = distance 1 (one letter different)
-   "Garcia, Maria" vs "Garcia, Marie" = distance 2 (two letters different)
-   Higher distance = less likely to be the same person

------------------------------------------------------------------------

### Checkpoint C: Key Validation

**Purpose**: Verify that our composite employee keys (name + department + hire date) are unique within each fiscal year. Duplicates would indicate a data problem.

```{r}
#| label: checkpoint-c-details

reconciliation$checkpoint_c$summary |>
  flextable::flextable() |>
  flextable::autofit() |>
  flextable::set_caption("Checkpoint C: Key Validation Summary")
```

```{r}
#| label: checkpoint-c-coverage

# This shows how many employees appear in 1 year, 2 years, etc.
# Useful for understanding employee turnover patterns

reconciliation$checkpoint_c$coverage_summary |>
  flextable::flextable() |>
  flextable::autofit() |>
  flextable::set_caption("Employee Coverage Across Fiscal Years")
```

```{r}
#| label: checkpoint-c-employee-counts-by-year

# SUPPLEMENTAL: Count unique employees per fiscal year at each pipeline stage
# This lets you verify no employees were lost during data manipulation

# Count from raw imported data (combined_df)
raw_counts <- combined_df |>
 dplyr::group_by(fiscal_year) |>
 dplyr::summarise(
   raw_rows = dplyr::n(),
   .groups = "drop"
 )

# Count from cleaned data (after name standardization, before pivot)
cleaned_counts <- cleaned_df |>
 dplyr::group_by(fiscal_year) |>
 dplyr::summarise(
   cleaned_rows = dplyr::n(),
   unique_employees = dplyr::n_distinct(employee_key),
   .groups = "drop"
 )

# Count from final long-format data
final_counts <- final_df |>
 dplyr::group_by(fiscal_year) |>
 dplyr::summarise(
   final_rows = dplyr::n(),
   unique_employees_final = dplyr::n_distinct(employee_key),
   .groups = "drop"
 )

# Join all counts together for comparison
employee_verification <- raw_counts |>
 dplyr::left_join(cleaned_counts, by = "fiscal_year") |>
 dplyr::left_join(final_counts, by = "fiscal_year")

employee_verification |>
 flextable::flextable() |>
 flextable::autofit() |>
 flextable::set_caption("Employee Counts by Fiscal Year (Pipeline Verification)")
```


**Column definitions for this new table**:

| Column | Source | What It Counts |
|--------|--------|----------------|
| `raw_rows` | combined_df | Total rows imported from Excel (should match Checkpoint A) |
| `cleaned_rows` | cleaned_df | Rows after cleaning (should equal raw_rows) |
| `unique_employees` | cleaned_df | Distinct employee_keys per year |
| `final_rows` | final_df | Rows after pivot to long format (will be higher - one row per earnings type) |
| `unique_employees_final` | final_df | Distinct employee_keys in final data (should match unique_employees) |

**What to look for**:

1. `raw_rows` should match your Checkpoint A source file row counts
2. `cleaned_rows` should equal `raw_rows` (no rows lost in cleaning)
3. `unique_employees` and `unique_employees_final` should be identical (no employees lost in pivot)
4. `final_rows` will be larger than `cleaned_rows` because the pivot creates one row per earnings type (Regular, Overtime, Other)




**What this does**:

-   Checks that no two records in the same fiscal year have the same employee_key
-   If duplicates exist, shows them for investigation
-   Coverage summary shows retention patterns (how many people span all 5 years vs just 1)

**Why this matters**:

-   Duplicate keys within a year = data quality problem (same person listed twice?)
-   Our analysis assumes one record per employee per year per earnings type

------------------------------------------------------------------------

### Checkpoint D: Completeness Verification

**Purpose**: Confirm that specific people you KNOW should be in the data actually appear. This catches silent filtering failures like the invisible character problem we found.

```{r}
#| label: checkpoint-d-entities

# Check each key entity defined in the config
# Shows whether they were found in their expected years

if (base::nrow(reconciliation$checkpoint_d$entity_check) > 0) {
  reconciliation$checkpoint_d$entity_check |>
    flextable::flextable() |>
    flextable::autofit() |>
    flextable::set_caption("Checkpoint D: Key Entity Verification")
} else {
  base::cat("No key entities defined in configuration.")
}
```

```{r}
#| label: checkpoint-d-totals

# Show our calculated totals by fiscal year
# These can be compared to published city figures

reconciliation$checkpoint_d$our_totals |>
  dplyr::mutate(
    total_compensation = scales::dollar(total_compensation, accuracy = 1)
  ) |>
  flextable::flextable() |>
  flextable::autofit() |>
  flextable::set_caption("Calculated Totals by Fiscal Year")
```

**What this does**:

-   For each person in `key_entities` config, checks if they appear with the right job title in expected years
-   `found = FALSE` means someone is missing who shouldn't be—investigate immediately
-   Also shows total compensation by year for comparison to published figures

**Why this matters**:

-   If the City Manager is missing from FY24, you'd look foolish presenting to Council
-   This is your "sanity check" that politically visible people are present

------------------------------------------------------------------------

### Overall Reconciliation Status

```{r}
#| label: overall-status

# Build a summary table showing pass/fail for each checkpoint

overall_summary <- dplyr::tibble(
  Checkpoint = c("A: Source Reconciliation",
                 "B: Name Variations", 
                 "C: Key Validation",
                 "D: Completeness",
                 "OVERALL"),
  Status = c(
    # Each checkpoint has a $pass element (TRUE/FALSE)
    base::ifelse(reconciliation$checkpoint_a$pass, "PASS", "FAIL"),
    
    # Checkpoint B always "passes" but may have warnings
    base::ifelse(reconciliation$checkpoint_b$pass, 
                 base::ifelse(reconciliation$checkpoint_b$has_warnings, 
                              "PASS (warnings)", "PASS"),
                 "FAIL"),
    
    base::ifelse(reconciliation$checkpoint_c$pass, "PASS", "FAIL"),
    base::ifelse(reconciliation$checkpoint_d$pass, "PASS", "FAIL"),
    
    # Overall passes only if A, C, and D all pass
    base::ifelse(reconciliation$overall_pass, "PASS", "FAIL")
  )
)

overall_summary |>
  flextable::flextable() |>
  flextable::autofit() |>
  flextable::bold(i = 5) |>  # Bold the OVERALL row
  flextable::set_caption("Reconciliation Summary")
```

**What this does**:

-   Summarizes all checkpoints in one table
-   OVERALL = PASS only if checkpoints A, C, and D all pass
-   Checkpoint B is informational (always passes, but warns you to review)

------------------------------------------------------------------------

## Step 4: Generate HTML Report

Create a standalone HTML file as audit evidence.

```{r}
#| label: generate-report

# Create the reports directory if it doesn't exist
if (!base::dir.exists(paths$reports)) {
  base::dir.create(paths$reports, recursive = TRUE)
}

# generate_reconciliation_report() builds an HTML file with all results
# It's defined in schertz_reconciliation.R

report_path <- generate_reconciliation_report(
  reconciliation,                    # All the checkpoint results
  output_path = paths$reports,       # Where to save the file
  test_mode = report_settings$test_mode  # Add "_TEST" to filename?
)

base::cat("Report saved to:", report_path)
```

**What this does**:

-   Creates a self-contained HTML file with all reconciliation details
-   Filename includes date and "\_TEST" suffix (if in test mode)
-   This is your audit artifact—you can hand it to anyone who questions your data

------------------------------------------------------------------------

## Step 5: Export Data

Save the final dataset for analysis.

```{r}
#| label: export-decision

# Warn if reconciliation failed, but don't stop
# Sometimes you need to export to investigate problems

if (!reconciliation$overall_pass) {
  warning("RECONCILIATION FAILED - Review issues before exporting!")
  base::cat("\nProceeding with export for review purposes, but data may have issues.\n")
}
```

```{r}
#| label: export-data

# Choose output directory based on test mode
output_dir <- base::ifelse(
  report_settings$test_mode,
  paths$output_test,   # Test outputs go to separate folder
  paths$data_clean     # Production outputs go to data_clean
)

# Create directory if needed
if (!base::dir.exists(output_dir)) {
  base::dir.create(output_dir, recursive = TRUE)
}

# Build filenames with optional _TEST suffix
test_suffix <- base::ifelse(report_settings$test_mode, "_TEST", "")

# Save as RDS (R's native format - preserves all data types perfectly)
rds_path <- base::file.path(output_dir, base::paste0("compensation_long", test_suffix, ".rds"))
saveRDS(final_df, file = rds_path)

# Save as CSV (universal format - can open in Excel, other tools)
csv_path <- base::file.path(output_dir, base::paste0("compensation_long", test_suffix, ".csv"))
readr::write_csv(final_df, file = csv_path)

base::cat("Data exported to:", output_dir, "\n")
base::cat("Files:\n")
base::cat("  -", base::basename(rds_path), "\n")
base::cat("  -", base::basename(csv_path), "\n")
```

**What this does**:

-   `saveRDS()` saves in R's native format—preserves dates, factors, everything perfectly
-   `write_csv()` saves as CSV for use in other tools
-   Test mode keeps test outputs separate from production data
-   `base::basename()` extracts just the filename (without folder path) for cleaner output

------------------------------------------------------------------------

## Step 6: Validation Plots

Visual verification that the data makes sense.

### Plot 1: City Manager Compensation

This verifies our key entity tracking works—we should see both City Managers.

```{r}
#| label: plot-city-manager
#| fig-width: 8
#| fig-height: 5

final_df |>
  # Filter to just City Manager, just Regular earnings
  dplyr::filter(
    job_title == "City Manager",
    earnings_type == "Regular"
  ) |>
  # Start the plot
  ggplot2::ggplot(
    ggplot2::aes(
      x = fiscal_year,     # X axis: fiscal year
      y = amount,          # Y axis: earnings amount
      group = name,        # Group by person (for separate lines)
      color = name         # Different color per person
    )
  ) +
  # Add line connecting each person's points
  ggplot2::geom_line(linewidth = 1) +
  # Add points at each data value
  ggplot2::geom_point(size = 3) +
  # Format Y axis as dollars
  ggplot2::scale_y_continuous(labels = scales::dollar_format()) +
  # Add labels
  ggplot2::labs(
    title = "City Manager Regular Earnings by Fiscal Year",
    x = "Fiscal Year",
    y = "Regular Earnings",
    color = "Employee"
  ) +
  # Clean theme
  ggplot2::theme_minimal()
```

**What this does**:

-   `filter()` narrows to just City Manager regular earnings
-   `aes()` defines the aesthetic mappings (what goes on each axis, how to group)
-   `geom_line()` draws lines connecting points
-   `geom_point()` draws dots at each data point
-   `scale_y_continuous(labels = ...)` formats the Y axis labels as dollars
-   `theme_minimal()` removes visual clutter

**Why it matters**: If Stephen Williams doesn't appear in FY23-24, something is wrong.

------------------------------------------------------------------------

### Plot 2: Total Compensation Growth

Shows the overall story—compensation doubling in 5 years.

```{r}
#| label: plot-total-growth
#| fig-width: 8
#| fig-height: 5

reconciliation$checkpoint_d$our_totals |>
  ggplot2::ggplot(
    ggplot2::aes(
      x = fiscal_year,           # X axis: fiscal year
      y = total_compensation,    # Y axis: total comp
      group = 1                  # Treat all points as one group (one line)
    )
  ) +
  # Draw the connecting line
  ggplot2::geom_line(linewidth = 1.5, color = "steelblue") +
  # Draw points at each year
  ggplot2::geom_point(size = 4, color = "steelblue") +
  # Add value labels above each point
  ggplot2::geom_text(
    ggplot2::aes(
      # Format as "$XXM" (millions)
      label = scales::dollar(total_compensation, scale = 1e-6, suffix = "M")
    ),
    vjust = -1  # Position above the point (negative = up)
  ) +
  # Format Y axis
  ggplot2::scale_y_continuous(
    labels = scales::dollar_format(scale = 1e-6, suffix = "M"),
    limits = c(0, NA)  # Start at 0, auto-scale the top
  ) +
  ggplot2::labs(
    title = "Total Employee Compensation by Fiscal Year",
    subtitle = "City of Schertz",
    x = "Fiscal Year",
    y = "Total Compensation"
  ) +
  ggplot2::theme_minimal()
```

**What this does**:

-   Uses the totals calculated during reconciliation
-   `scale = 1e-6` divides by 1 million (so 30000000 becomes 30)
-   `suffix = "M"` adds "M" after the number
-   `limits = c(0, NA)` forces Y axis to start at zero (NA means auto-calculate max)
-   `vjust = -1` moves text labels up (negative values move up in ggplot)

------------------------------------------------------------------------

### Plot 3: Year-over-Year Growth Rate

Shows the growth rate each year—key for your sustainability argument.

```{r}
#| label: plot-growth-rate
#| fig-width: 8
#| fig-height: 5

# First, calculate growth rates
growth_data <- reconciliation$checkpoint_d$our_totals |>
  dplyr::arrange(fiscal_year) |>  # Ensure chronological order
  dplyr::mutate(
    # lag() gets the previous row's value
    prior_total = dplyr::lag(total_compensation),
    # Growth rate formula: (new - old) / old
    growth_rate = (total_compensation - prior_total) / prior_total,
    # Convert to percentage
    growth_pct = growth_rate * 100
  )

# Now plot
growth_data |>
  # Remove the first year (no prior year to compare to, so growth_rate is NA)
  dplyr::filter(!base::is.na(growth_rate)) |>
  ggplot2::ggplot(ggplot2::aes(x = fiscal_year, y = growth_pct)) +
  # Bar chart
  ggplot2::geom_col(fill = "steelblue") +
  # Labels on top of bars
  ggplot2::geom_text(
    ggplot2::aes(label = base::paste0(base::round(growth_pct, 1), "%")),
    vjust = -0.5  # Position above bar
  ) +
  # Reference line at 0%
  ggplot2::geom_hline(yintercept = 0, linetype = "dashed") +
  # Add padding at top so labels don't get cut off
  # expansion(mult = c(bottom, top)) - mult means "multiply axis range by this"
  # c(0, 0.15) means 0% padding at bottom, 15% padding at top
  ggplot2::scale_y_continuous(expand = ggplot2::expansion(mult = c(0, 0.15))) +
  ggplot2::labs(
    title = "Year-over-Year Compensation Growth",
    subtitle = "City of Schertz",
    x = "Fiscal Year",
    y = "Growth Rate (%)"
  ) +
  ggplot2::theme_minimal()
```

**What this does**:

-   `lag()` shifts values down one row, so you can compare each year to the prior year
-   `(new - old) / old` is the standard growth rate formula
-   `geom_col()` creates a bar chart (bars start at 0)
-   `geom_hline()` draws a horizontal reference line
-   `expansion(mult = c(0, 0.15))` adds 15% padding at top of Y axis so labels fit

**The key insight**: `expansion()` is better than hardcoding `limits = c(0, 50)` because it automatically scales with your data. If next year's growth is 60%, it still works.

------------------------------------------------------------------------

## Summary: How the Pipeline Protects You

| Risk | How the Pipeline Addresses It |
|----------------|--------------------------------------------------------|
| Rows dropped during import | Checkpoint A compares row counts |
| Dollars don't match source | Checkpoint A compares totals |
| Invisible characters cause filter failures | `fix_spaces()` normalizes automatically |
| Same person appears as two people | Checkpoint B flags similar names |
| Duplicate records inflate totals | Checkpoint C checks key uniqueness |
| Key person missing from data | Checkpoint D verifies key entities |
| No audit trail | HTML report documents everything |

------------------------------------------------------------------------

## Key Functions Reference

| Function | File | Purpose |
|----------------------------|------------------|--------------------------|
| `run_pipeline_with_intermediates()` | schertz_processing.R | Orchestrates all processing stages |
| `run_reconciliation()` | schertz_reconciliation.R | Runs all four checkpoints |
| `generate_reconciliation_report()` | schertz_reconciliation.R | Creates HTML audit report |
| `profile_new_file()` | schertz_profiler.R | Examines a new Excel file before incorporating |
| `fix_spaces()` | schertz_processing.R | Removes invisible Unicode spaces |
| `standardize_name()` | schertz_processing.R | Normalizes names (strips middle initials, etc.) |
| `parse_currency()` | schertz_processing.R | Converts "\$1,234.56" to numeric |
| `parse_flex_date()` | schertz_processing.R | Handles both Excel serial dates and text dates |

------------------------------------------------------------------------

## What to Do When Things Go Wrong

| Symptom | Likely Cause | Solution |
|--------------------|------------------------------|----------------------|
| Checkpoint A fails (row mismatch) | File changed, or import filter applied | Re-download source file, check for hidden filters |
| Checkpoint A fails (total mismatch) | Currency parsing issue | Check for unusual formats in source |
| Checkpoint B shows many similar names | Normal for first run | Review pairs, add corrections to config |
| Checkpoint C shows duplicate keys | Same person twice in same year | Investigate source data |
| Checkpoint D shows missing entity | Invisible character, or name changed | Check entity spelling, run profiler on source file |
| Plot missing expected person | Job title doesn't match exactly | Check exact spelling with `distinct(job_title)` |
